 # 默认副本系数为3
default.replication.factor=3
# 自动创建Topic开启
auto.create.topics.enable=true
cluster.id=lEZffL5fRROYGapsqr_pOQ
#一个broker在集群中的唯一标示，要求是正数。在改变IP地址，不改变broker.id的话不会影响consumers
broker.id=1
 
#listeners=PLAINTEXT://0.0.0.0:9092
 
#advertised.listeners=PLAINTEXT://kafka:9092
 
#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SS
 
# broker 处理消息的最大线程数，一般情况下不需要去修改
num.network.threads=3
 
# broker处理磁盘IO 的线程数 ，数值应该大于你的硬盘数
num.io.threads=8
 
#  socket的发送缓冲区（SO_SNDBUF）
socket.send.buffer.bytes=102400
 
# socket的接收缓冲区 (SO_RCVBUF)
socket.receive.buffer.bytes=102400
 
# socket请求的最大字节数。为了防止内存溢出，message.max.bytes必然要小于
socket.request.max.bytes=104857600
 
#kafka数据的存放地址，多个地址的话用逗号分割 /tmp/kafka-logs-1，/tmp/kafka-logs-2
log.dirs=/kafka/kafka-logs
 
# 每个topic的分区个数，更多的partition会产生更多的segment file
num.partitions=1
 
num.recovery.threads.per.data.dir=1
 
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
 
# 当达到下面的消息数量时，会将数据flush到日志文件中。默认10000
#log.flush.interval.messages=10000
 
# 当达到下面的时间(ms)时，执行一次强制的flush操作。interval.ms和interval.messages无论哪个达到，都会flush。默认3000ms
#log.flush.interval.ms=1000
 
# 日志保存时间 (hours|minutes)，默认为7天（168小时）。超过这个时间会根据policy处理数据。bytes和minutes无论哪个先达到都会触发。
log.retention.hours=168
 
#log.retention.bytes=1073741824
 
# 控制日志segment文件的大小，超出该大小则追加到一个新的日志segment文件中（-1表示没有限制）
log.segment.bytes=1073741824
 
# 日志片段文件的检查周期，查看它们是否达到了删除策略的设置（log.retention.hours或log.retention.bytes）
log.retention.check.interval.ms=300000
 
# Zookeeper quorum设置。如果有多个使用逗号分割 例如 ip:prot,ip:prot,ip:prot
zookeeper.connect=localhost:2181
 
# 连接zk的超时时间
zookeeper.connection.timeout.ms=6000
 
# ZooKeeper集群中leader和follower之间的同步实际